import argparse
import pickle


def get_args():
    parser = argparse.ArgumentParser()
    exist = set()
    args_fix = "beam=3, bpe=None, buffer_size=1, cpu=False, criterion='cross_entropy', data=['/home/lyn/liuwei/Subjective_Bias/fairseq/data_bin/cluster_0'], dataset_impl=None, decoding_format=None, diverse_beam_groups=-1, diverse_beam_strength=0.5, empty_cache_freq=0, force_anneal=None, fp16=False, fp16_init_scale=128, fp16_scale_tolerance=0.0, fp16_scale_window=None, gen_subset='test', input='-', iter_decode_eos_penalty=0.0, iter_decode_force_max_iter=False, iter_decode_max_iter=10, iter_decode_with_beam=1, iter_decode_with_external_reranker=False, lazy_load=True, left_pad_source='False', left_pad_target='False', lenpen=1, log_format=None, log_interval=1000, lr_scheduler='fixed', lr_shrink=0.1, match_source_len=False, max_len_a=0, max_len_b=200, max_sentences=1, max_source_positions=700, max_target_positions=120, max_tokens=None, memory_efficient_fp16=False, min_len=1, min_loss_scale=0.0001, model_overrides='{}', momentum=0.99, nbest=1, no_beamable_mm=False, no_early_stop=False, no_progress_bar=False, no_repeat_ngram_size=0, num_shards=1, num_workers=1, optimizer='nag', path='/home/lyn/liuwei/Subjective_Bias/fairseq/checkpoints/cluster_0-8e-04-4/checkpoint_last.pt', prefix_size=0, print_alignment=True, print_step=False, quiet=False, raw_text=False, remove_bpe='@@ ', replace_unk=None, required_batch_size_multiple=8, results_path=None, retain_iter_history=False, sacrebleu=False, sampling=False, sampling_topk=-1, sampling_topp=-1.0, score_reference=False, seed=1, shard_id=0, skip_invalid_size_inputs_valid_test=False, source_lang=None, target_lang=None, task='summ_cnndm', temperature=1.0, tensorboard_logdir='', threshold_loss_scale=None, tokenizer=None, unkpen=0, unnormalized=False, upsample_primary=1, user_dir=None, warmup_updates=0, weight_decay=0.0, activation_dropout=0.0, activation_fn='relu', adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, arch='cnndm', attention_dropout=0.0, best_checkpoint_metric='loss', bpe=None, bucket_cap_mb=25, clip_norm=0.1, cpu=False, criterion='label_smoothed_cross_entropy', cross_self_attention=False, curriculum=0, data='/home/lyn/liuwei/Subjective_Bias/fairseq/data_bin/cluster_0', dataset_impl=None, ddp_backend='c10d', decoder_attention_heads=16, decoder_embed_dim=512, decoder_embed_path='/home/lyn/liuwei/Subjective_Bias/fairseq/data_bin/model_cnndm_512.vec', decoder_ffn_embed_dim=2048, decoder_input_dim=512, decoder_layerdrop=0, decoder_layers=6, decoder_layers_to_keep=None, decoder_learned_pos=False, decoder_normalize_before=True, decoder_out_embed_dim=512, decoder_output_dim=512, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_port=-1, distributed_rank=0, distributed_world_size=1, dropout=0.1, empty_cache_freq=0, encoder_attention_heads=16, encoder_embed_dim=512, encoder_embed_path='/home/lyn/liuwei/Subjective_Bias/fairseq/data_bin/model_cnndm_512.vec', encoder_ffn_embed_dim=2048, encoder_layerdrop=0, encoder_layers=6, encoder_layers_to_keep=None, encoder_learned_pos=False, encoder_normalize_before=True, fast_stat_sync=False, find_unused_parameters=False, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=True, fp16_init_scale=128, fp16_scale_tolerance=0.0, fp16_scale_window=None, keep_interval_updates=-1, keep_last_epochs=3, label_smoothing=0.1, layer_wise_attention=False, layernorm_embedding=False, left_pad_source=True, left_pad_target=False, load_alignments=False, log_format='tqdm', log_interval=1000, lr=[0.0008], lr_scheduler='inverse_sqrt', max_epoch=10, max_sentences=None, max_sentences_valid=None, max_source_positions=700, max_target_positions=120, max_tokens=8192, max_tokens_valid=8192, max_update=0, maximize_best_checkpoint_metric=False, memory_efficient_fp16=True, min_loss_scale=0.0001, min_lr=-1, no_cross_attention=False, no_epoch_checkpoints=False, no_last_checkpoints=False, no_progress_bar=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_token_positional_embeddings=False, num_workers=1, optimizer='adam', optimizer_overrides='{}', required_batch_size_multiple=8, reset_dataloader=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='/home/lyn/liuwei/Subjective_Bias/fairseq/checkpoints/cluster_0-8e-04-4', save_interval=1, save_interval_updates=0, seed=1, sentence_avg=False, share_all_embeddings=False, share_decoder_input_output_embed=False, share_input_output_embed=False, skip_invalid_size_inputs_valid_test=True, source_lang='src', target_lang='tgt', task='translation', tensorboard_logdir='/home/lyn/liuwei/Subjective_Bias/fairseq/tb_log/cluster_0-8e-04-4', threshold_loss_scale=None, tokenizer=None, train_subset='train', truncate_source=True, update_freq=[8], upsample_primary=1, use_bmuf=False, user_dir=None, valid_subset='valid', validate_interval=1, warmup_init_lr=0, warmup_updates=1000, weight_decay=0.01"
    for item in args_fix.split(", "):
        k, v = item.split('=')
        if k not in exist:
            exist.add(k)
            parser.add_argument('--' + k, default=eval(v))
            print(k, v)
    args = parser.parse_args()
    return args


args = get_args()
pickle.dump(args, open("./args_0", "wb"))
